{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54d1c43-4b7f-4917-939f-a964f6f3dafc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa67fa07-1395-4aab-a356-72bdb302f6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d12d766-3ca8-4012-9da2-248be80bb6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerryliu/Programming/llama_index/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.composability.joint_qa_summary import QASummaryGraphBuilder\n",
    "from llama_index import SimpleDirectoryReader, ServiceContext, LLMPredictor\n",
    "from llama_index.composability import ComposableGraph\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7cdaf9d-cfbd-4ced-8d4e-6eef8508224d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader('../paul_graham_essay/data')\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bba68f3-2743-437e-93b6-ce9ba92e40c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.llm_predictor.base:Unknown max input size for gpt-3.5-turbo, using defaults.\n",
      "Unknown max input size for gpt-3.5-turbo, using defaults.\n"
     ]
    }
   ],
   "source": [
    "llm_predictor_gpt4 = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\"))\n",
    "service_context_gpt4 = ServiceContext.from_defaults(llm_predictor=llm_predictor_gpt4, chunk_size_limit=1024)\n",
    "\n",
    "llm_predictor_chatgpt = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"))\n",
    "service_context_chatgpt = ServiceContext.from_defaults(llm_predictor=llm_predictor_chatgpt, chunk_size_limit=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16216dfb-35ea-49ac-b651-2e8a9e423512",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 20729 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 20729 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "# NOTE: can also specify an existing docstore, service context, summary text, qa_text, etc.\n",
    "graph_builder = QASummaryGraphBuilder(service_context=service_context_gpt4)\n",
    "graph = graph_builder.build_graph_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec542141-a0ed-4fb7-8fe7-3ba0027eb6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph.save_to_disk('test_qa_summary_graph.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19834e20-5b11-4b08-920f-d05107359980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph = ComposableGraph.load_from_disk('test_qa_summary_graph.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7716977-7f09-4e82-93d7-fa815f327a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set query config\n",
    "query_configs = [\n",
    "    {\n",
    "        \"index_struct_type\": \"simple_dict\",\n",
    "        \"query_mode\": \"default\",\n",
    "        \"query_kwargs\": {\n",
    "            \"similarity_top_k\": 1\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"index_struct_type\": \"list\",\n",
    "        \"query_mode\": \"default\",\n",
    "        \"query_kwargs\": {\n",
    "            \"response_mode\": \"tree_summarize\",\n",
    "            \"use_async\": True,\n",
    "            \"verbose\": True\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"index_struct_type\": \"tree\",\n",
    "        \"query_mode\": \"default\",\n",
    "        \"query_kwargs\": {\n",
    "            \"verbose\": True\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae60000b-403c-4350-af32-71e26cc68a75",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">[Level 0] Current response: ANSWER: 2\n",
      "\n",
      "This summary was selected because the question asks for a summary of the author's life, which implies needing a summarized version rather than a specific context from the documents. Hence, choice 2 is more relevant for summarization queries.\n",
      "INFO:llama_index.indices.tree.leaf_query:>[Level 0] Selected node: [2]/[2]\n",
      ">[Level 0] Selected node: [2]/[2]\n",
      ">[Level 0] Selected node: [2]/[2]\n",
      ">[Level 0] Node [2] Summary text: Use this index for summarization queries\n",
      "\u001b[36;1m\u001b[1;3m> Got node text: \t\t\n",
      "\n",
      "What I Worked On\n",
      "\n",
      "February 2021\n",
      "\n",
      "Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supp...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: fields would be mere domain knowledge. What I discovered when I got to college was that the other fields took up so much of the space of ideas that there wasn't much left for these supposed ultimat...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: mean the sort of AI in which a program that's told \"the dog is sitting on the chair\" translates this into some formal representation and adds it to the list of things it knows.\n",
      "\n",
      "What these programs...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: make enough to survive. And as an artist you could be truly independent. You wouldn't have a boss, or even need to get research funding.\n",
      "\n",
      "I had always liked looking at paintings. Could I make them?...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: fall. This was now only weeks away. My nice landlady let me leave my stuff in her attic. I had some money saved from consulting work I'd done in grad school; there was probably enough to last a yea...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: information-theoretic sense. [4]\n",
      "\n",
      "I liked painting still lives because I was curious about what I was seeing. In everyday life, we aren't consciously aware of much we're seeing. Most visual percept...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: people than sales people (though sales is a real skill and people who are good at it are really good at it), that it leads to bugs when code is edited by too many people, that cheap office space is...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: at RISD, but otherwise I was basically teaching myself to paint, and I could do that for free. So in 1993 I dropped out. I hung around Providence for a bit, and then my college friend Nancy Parmet ...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: and Robert wrote some to resize images and set up an http server to serve the pages. Then we tried to sign up galleries. To call this a difficult sale would be an understatement. It was difficult t...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: in September, but we got more ambitious about the software as we worked on it. Eventually we managed to build a WYSIWYG site builder, in the sense that as you were creating pages, they looked exact...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: of some clever insight that we set the price low. We had no idea what businesses paid for things. $300 a month seemed like a lot of money to us.\n",
      "\n",
      "We did a lot of things right by accident like that....\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: bought us it felt like going from rags to riches. Since we were going to California, I bought a car, a yellow 1998 VW GTI. I remember thinking that its leather seats alone were by far the most luxu...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: old patterns, except now there were doors where there hadn't been. Now when I was tired of walking, all I had to do was raise my hand, and (unless it was raining) a taxi would stop to pick me up. N...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: I doing this? If this vision had to be realized as a company, then screw the vision. I'd build a subset that could be done as an open source project.\n",
      "\n",
      "Much to my surprise, the time I spent working ...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: of the most conspicuous patterns I've noticed in my life is how well it has worked, for me at least, to work on things that weren't prestigious. Still life has always been the least prestigious for...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: start a startup. Maybe they'd be able to avoid the worst of the mistakes we'd made.\n",
      "\n",
      "So I gave this talk, in the course of which I told them that the best sources of seed funding were successful st...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: due to our ignorance about investing. We needed to get experience as investors. What better way, we thought, than to fund a whole bunch of startups at once? We knew undergrads got temporary jobs at...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: in. We also noticed that the startups were becoming one another's customers. We used to refer jokingly to the \"YC GDP,\" but as YC grows this becomes less and less of a joke. Now lots of startups ge...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: day in 2010, when he was visiting California for interviews, Robert Morris did something astonishing: he offered me unsolicited advice. I can only remember him doing that once before. One day at Vi...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: took a while to get back into shape, but it was at least completely engaging. [18]\n",
      "\n",
      "I spent most of the rest of 2014 painting. I'd never been able to work so uninterruptedly before, and I got to be...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: 2019. It was fortunate that I had a precisely defined goal, or it would have been hard to keep at it for so long.\n",
      "\n",
      "I wrote this new Lisp, called Bel, in itself in Arc. That may sound like a contrad...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: Italian words for abstract concepts can nearly always be predicted from their English cognates (except for occasional traps like polluzione). It's the everyday words that differ. So if you string t...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: that our experience with Y Combinator also teaches: Customs continue to constrain you long after the restrictions that caused them have disappeared. Customary VC practice had once, like the customs...\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m> Got node text: up a deeply rooted tree.\n",
      "\n",
      "[19] One way to get more precise about the concept of invented vs discovered is to talk about space aliens. Any sufficiently advanced alien civilization would certainly kn...\n",
      "\u001b[0mINFO:llama_index.indices.common_tree.base:> Building index from nodes: 6 chunks\n",
      "> Building index from nodes: 6 chunks\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3833 request_id=5bd6aba916b8fc4e87f26cabd582d6f0 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3833 request_id=5bd6aba916b8fc4e87f26cabd582d6f0 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=11289 request_id=ad00122a64fd8bf20c1dcda728dac40b response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=11289 request_id=ad00122a64fd8bf20c1dcda728dac40b response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=13232 request_id=f9b8ea19c201d9aaa21754483d1b7d57 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=13232 request_id=f9b8ea19c201d9aaa21754483d1b7d57 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=14349 request_id=c5fe0db7485b99bec0b138f336d552e5 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=14349 request_id=c5fe0db7485b99bec0b138f336d552e5 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=16785 request_id=b0551838004d5b9b8ee51b9aa91453c1 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=16785 request_id=b0551838004d5b9b8ee51b9aa91453c1 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=20631 request_id=f48ed7147f298d67fd2519e418e0ac71 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=20631 request_id=f48ed7147f298d67fd2519e418e0ac71 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=24685 request_id=d74bc6945f810d15bd9d5fa8c140eb6f response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=24685 request_id=d74bc6945f810d15bd9d5fa8c140eb6f response_code=200\n",
      "\u001b[36;1m\u001b[1;3m> Got node text: The author's life has been a journey of exploration, learning, and creating. From their early fascination with computers and painting, they moved on to study art in Italy and computer science in th...\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = graph.query(\n",
    "    \"Can you give me a summary of the author's life?\", \n",
    "    query_configs=query_configs, \n",
    "    service_context=service_context_gpt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca12b3ac-fcc2-4998-917a-16f568b59623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author's life has been a journey of exploration, learning, and creating, encompassing a diverse range of interests such as computers, painting, and writing. They studied art in Italy and computer science in the United States before co-founding Viaweb, which was later sold to Yahoo. They also became an influential online essayist and co-founded the successful startup accelerator Y Combinator. Additionally, they worked on designing a new programming language called Bel. After handing over Y Combinator's leadership to Sam Altman, the author returned to painting for a while, but later lost interest, illustrating their continuous search for personal growth and passion-driven endeavors.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4488669d-0f67-48c9-994c-bd7a42498ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">[Level 0] Current response: ANSWER: 1\n",
      "\n",
      "The question, \"What did the author do growing up?\" asks for specific context from documents about the author's experiences or activities during their childhood. Choice 1 mentions retrieval of specific context from documents, which is more in line with answering this type of question than summarization queries mentioned in Choice 2.\n",
      "INFO:llama_index.indices.tree.leaf_query:>[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Node [1] Summary text: Use this index for queries that require retrieval of specific context from documents.\n",
      "\u001b[36;1m\u001b[1;3m> Got node text: Growing up, the author worked on writing short stories and programming on the IBM 1401, a computer used in their school district. They also experimented with programming on a TRS-80 microcomputer, ...\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = graph.query(\n",
    "    \"What did the author do growing up?\", \n",
    "    query_configs=query_configs,\n",
    "    service_context=service_context_gpt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1004bedc-f3c9-4643-9e65-f869a08dec32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing up, the author worked on writing short stories and programming on the IBM 1401 computer. They also experimented with programming on a TRS-80 microcomputer, creating simple games, a model rocket prediction program, and a word processor for their father.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff95db5f-7cbe-4ed7-83ff-27e00b94e7da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">[Level 0] Current response: ANSWER: 1\n",
      "\n",
      "This summary was selected in relation to the question because it involves retrieval of specific context from documents, which is necessary to know what the author did during his time in art school. Choice 2 is focused on summarization queries, which isn't related to the specific detail needed to answer the question.\n",
      "INFO:llama_index.indices.tree.leaf_query:>[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Node [1] Summary text: Use this index for queries that require retrieval of specific context from documents.\n",
      "\u001b[36;1m\u001b[1;3m> Got node text: The author took classes in fundamental subjects like drawing, color, and design during the foundation program at RISD. He also prepared for the entrance exam at the Accademia di Belli Arti in Flore...\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = graph.query(\n",
    "    \"What did the author do during his time in art school?\", \n",
    "    query_configs=query_configs,\n",
    "    service_context=service_context_gpt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75d4f291-88fe-4a51-8650-af77ed35766e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During his time in art school, the author took classes in fundamental subjects, such as drawing, color, and design, as part of the foundation program at RISD. He also prepared for the entrance exam at the Accademia di Belli Arti in Florence, which involved learning Italian.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9bf34-d242-4fbd-b67a-1dc99b387a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
