{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "0b692c73",
            "metadata": {},
            "source": [
                "# Using the GPTMilvusIndex"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1e7787c2",
            "metadata": {},
            "source": [
                "In this notebook we are going to show a quick demo of using the MilvusIndex. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "47264e32",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:20:23.988789Z",
                    "start_time": "2023-02-10T12:20:23.967877Z"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/filiphaltmayer/miniconda3/envs/llama/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import logging\n",
                "import sys\n",
                "\n",
                "# Uncomment to see debug logs\n",
                "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
                "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
                "\n",
                "from gpt_index import GPTMilvusIndex, SimpleDirectoryReader, Document\n",
                "from IPython.display import Markdown, display\n",
                "import textwrap"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "f9b97a89",
            "metadata": {},
            "source": [
                "### Setup OpenAI\n",
                "Lets first begin by adding the openai api key. This will allow us to access openai for embeddings and to use chatgpt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "0c9f4d21-145a-401e-95ff-ccb259e8ef84",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:20:24.908956Z",
                    "start_time": "2023-02-10T12:20:24.537064Z"
                },
                "pycharm": {
                    "is_executing": true
                }
            },
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ[\"OPENAI_API_KEY\"] = \"sk-\""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "59ff935d",
            "metadata": {},
            "source": [
                "### Generate our data\n",
                "With our LLM set, lets start using the Milvus Index. As a first example, lets generate a document from the file found in the `paul_graham_essay/data` folder. In this folder there is a single essay from Paul Graham titled `What I Worked On`. To generate the documents we will use the SimpleDirectoryReader."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:20:30.175678Z",
                    "start_time": "2023-02-10T12:20:30.172456Z"
                },
                "pycharm": {
                    "is_executing": true
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Document ID: 933666c4-2833-475a-a3d5-d279a0c174fa Document Hash: 77ae91ab542f3abb308c4d7c77c9bc4c9ad0ccd63144802b7cbe7e1bb3a4094e\n"
                    ]
                }
            ],
            "source": [
                "# load documents\n",
                "documents = SimpleDirectoryReader('../paul_graham_essay/data').load_data()\n",
                "print('Document ID:', documents[0].doc_id, 'Document Hash:', documents[0].doc_hash)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "dd270925",
            "metadata": {},
            "source": [
                "### Create an index across the data\n",
                "Now that we have a document, we can can create an index and insert the document. For the index we will use a GPTMilvusIndex. GPTMilvusIndex takes in a few arguments:\n",
                "\n",
                "- collection_name (str, optional): The name of the collection where data will be stored. Defaults to \"llamalection\".\n",
                "- index_params (dict, optional): The index parameters for Milvus, if none are provided an HNSW index will be used. Defaults to None.\n",
                "- search_params (dict, optional): The search parameters for a Milvus query. If none are provided, default params will be generated. Defaults to None.\n",
                "- dim (int, optional): The dimension of the embeddings. If it is not provided, collection creation will be done on first insert. Defaults to None.\n",
                "- host (str, optional): The host address of Milvus. Defaults to \"localhost\".\n",
                "- port (int, optional): The port of Milvus. Defaults to 19530.\n",
                "- user (str, optional): The username for RBAC. Defaults to \"\".\n",
                "- password (str, optional): The password for RBAC. Defaults to \"\".\n",
                "- use_secure (bool, optional): Use https. Defaults to False.\n",
                "- overwrite (bool, optional): Whether to overwrite existing collection with same name. Defaults to False.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "ba1558b3",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:20:33.735897Z",
                    "start_time": "2023-02-10T12:20:30.404245Z"
                },
                "pycharm": {
                    "is_executing": true
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 17617 tokens\n"
                    ]
                }
            ],
            "source": [
                "# Create an index over the documnts\n",
                "index = GPTMilvusIndex.from_documents(documents, overwrite=True)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "04304299-fc3e-40a0-8600-f50c3292767e",
            "metadata": {},
            "source": [
                "# Query the data\n",
                "Now that we have our document stored in the index, we can ask questions against the index. The index will use the data stored in itself as the knowledge base for chatgpt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "35369eda",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:20:51.328762Z",
                    "start_time": "2023-02-10T12:20:33.822688Z"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 4028 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 6 tokens\n"
                    ]
                }
            ],
            "source": [
                "response = index.query(\"What did the author learn?\", )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "bedbb693-725f-478f-be26-fa7180ea38b2",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:20:51.337062Z",
                    "start_time": "2023-02-10T12:20:51.330857Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  The author learned that working on things that are not prestigious can be a good thing, as it can\n",
                        "lead to discovering something real and avoiding the wrong track. The author also learned that\n",
                        "ignorance can be beneficial, as it can lead to discovering something new and unexpected. The author\n",
                        "also learned the importance of working hard, even at the parts of the job they don't like, in order\n",
                        "to set an example for others. The author also learned the value of unsolicited advice, as it can be\n",
                        "beneficial in unexpected ways, such as when Robert Morris suggested that the author should make sure\n",
                        "Y Combinator wasn't the last cool thing they did.\n"
                    ]
                }
            ],
            "source": [
                "print(textwrap.fill(str(response), 100))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "99212d33",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:21:10.337294Z",
                    "start_time": "2023-02-10T12:20:51.338718Z"
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 4072 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
                    ]
                }
            ],
            "source": [
                "response = index.query(\"What was a hard moment for the author?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "1a720ad6",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2023-02-10T12:21:10.355872Z",
                    "start_time": "2023-02-10T12:21:10.343486Z"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " A hard moment for the author was when he was dealing with urgent problems during YC and about 60%\n",
                        "of them had to do with Hacker News, a news aggregator he had created. He was overwhelmed by the\n",
                        "amount of work he had to do to keep Hacker News running, and it was taking away from his ability to\n",
                        "focus on other projects. He was also haunted by the idea that his own work ethic set the upper bound\n",
                        "for how hard everyone else worked, so he felt he had to work very hard. He was also dealing with\n",
                        "disputes between cofounders, figuring out when people were lying to them, and fighting with people\n",
                        "who maltreated the startups. On top of this, he was given unsolicited advice from Robert Morris to\n",
                        "make sure Y Combinator wasn't the last cool thing he did, which made him consider quitting.\n"
                    ]
                }
            ],
            "source": [
                "print(textwrap.fill(str(response), 100))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "947dbd1d",
            "metadata": {},
            "source": [
                "We can also save the configuration of the index for later use. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "b0b6d770",
            "metadata": {},
            "outputs": [],
            "source": [
                "saved_index = index.save_to_dict()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "64cc925b",
            "metadata": {},
            "source": [
                "This next test shows that overwriting removes the previous data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "8d641e24",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 5 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 44 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 5 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Res: \n",
                        "The author is unknown.\n"
                    ]
                }
            ],
            "source": [
                "index = GPTMilvusIndex.from_documents([Document(\"The answer is ten.\")], overwrite=True)\n",
                "res = index.query(\"Who is the author?\")\n",
                "\n",
                "print(flush=True)\n",
                "print(\"Res:\", res, flush=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d8123529",
            "metadata": {},
            "source": [
                "The next test shows reloading the index and also shows adding additional data to an already existing  index."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "a5c429a4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 44 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 5 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "The answer is ten.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 17617 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 41 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 5 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Ten.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 3720 tokens\n",
                        "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 5 tokens\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "The author of the text is Paul Graham, co-founder of Y Combinator.\n"
                    ]
                }
            ],
            "source": [
                "del index\n",
                "\n",
                "index = GPTMilvusIndex.load_from_dict(saved_index)\n",
                "print(index.query(\"What is the answer.\"))\n",
                "\n",
                "index = GPTMilvusIndex.from_documents(documents, overwrite = False)\n",
                "print(index.query(\"What is the answer?\"))\n",
                "print(index.query(\"Who is the author?\"))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
